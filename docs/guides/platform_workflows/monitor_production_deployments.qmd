---
title: 'Monitor production deployments'
---

Monitor Xorq Flight server performance using Prometheus metrics and OpenTelemetry tracing. This guide shows you how to enable metrics, query them, set up alerts, and view traces.

**Goal**: Set up monitoring for your Xorq deployments so you can track performance, detect issues, and understand system behavior.

## Prerequisites

Before you start, you need:

- [Xorq installed](../../getting_started/installation.qmd)
- A deployed Xorq Flight server (see [Deploy models to production](../ml_workflows/deploy_models_to_production.qmd))
- Prometheus installed (for scraping metrics)
- Optional: OpenTelemetry collector (for distributed tracing)

## Enable Prometheus metrics

Enable metrics when starting your Flight server.

### Start server with metrics

Start the server with the `--prometheus-port` flag:

```bash
xorq serve-unbound builds/<build_hash> \
  --host 0.0.0.0 \
  --port 8080 \
  --prometheus-port 9090 \
  --to_unbind_tag source_input
```

**What happens**:

- Metrics are exposed on port 9090 (separate from the Flight server port)
- Server logs: `Prometheus metrics available at :9090`
- Metrics are available at `http://localhost:9090/metrics`

**Expected output**:
```
Loading expression from builds/050dac72b4d8
Prometheus metrics available at :9090
Serving expression from 'builds/050dac72b4d8' on grpc://0.0.0.0:8080
```

:::{.callout-important}
## Dependencies required

Prometheus metrics require these packages:

- `opentelemetry-exporter-prometheus`
- `prometheus-client`

Install them with:
```bash
pip install opentelemetry-exporter-prometheus prometheus-client
```

If packages are missing, the server starts but metrics won't be available.
:::

### Verify metrics endpoint

Check that metrics are accessible:

```bash
curl http://localhost:9090/metrics
```

**Expected output**:
```
# HELP flight_server_requests_total Total Flight RPC requests
# TYPE flight_server_requests_total counter
flight_server_requests_total{method="do_get"} 0

# HELP flight_server_request_duration_seconds Request duration in seconds
# TYPE flight_server_request_duration_seconds histogram
flight_server_request_duration_seconds_bucket{method="do_get",le="0.005"} 0
flight_server_request_duration_seconds_bucket{method="do_get",le="0.01"} 0
...

# HELP flight_server_active_streams Active concurrent streams
# TYPE flight_server_active_streams gauge
flight_server_active_streams 0

# HELP flight_server_bytes_total Total bytes transferred
# TYPE flight_server_bytes_total counter
flight_server_bytes_total{method="do_get"} 0

# HELP flight_server_rows_total Total rows processed
# TYPE flight_server_rows_total counter
flight_server_rows_total{method="do_get"} 0

# HELP flight_server_throughput_rows_per_sec Rows per second throughput
# TYPE flight_server_throughput_rows_per_sec histogram
flight_server_throughput_rows_per_sec_bucket{method="do_get",le="100"} 0
...
```

## Available metrics

Xorq Flight server exposes these metrics:

### Request metrics

- **`flight_server.requests_total`**: Total number of Flight RPC requests (counter)
- **`flight_server.request_duration_seconds`**: Request latency histogram (histogram)
- **`flight_server.active_streams`**: Current number of active concurrent streams (gauge)

### Throughput metrics

- **`flight_server.bytes_total`**: Total bytes transferred (counter)
- **`flight_server.rows_total`**: Total rows processed (counter)
- **`flight_server.throughput_rows_per_sec`**: Rows per second throughput (histogram)

All metrics include a `method` label indicating the RPC method (`do_get`, `do_put`, etc.).

## Query metrics

Query metrics using `curl` or PromQL.

### Query with curl

Get specific metrics:

```bash
# Request count
curl http://localhost:9090/metrics | grep requests_total

# Latency histogram
curl http://localhost:9090/metrics | grep request_duration_seconds

# Active streams
curl http://localhost:9090/metrics | grep active_streams
```

**Expected output**:
```
flight_server_requests_total{method="do_get"} 42
flight_server_request_duration_seconds_bucket{method="do_get",le="0.1"} 38
flight_server_active_streams 2
```

### Query with PromQL

Use PromQL in Prometheus or Grafana:

**Request rate (requests per second)**:
```promql
rate(flight_server_requests_total[5m])
```

**P95 latency**:
```promql
histogram_quantile(0.95, flight_server_request_duration_seconds)
```

**Current throughput**:
```promql
rate(flight_server_rows_total[5m])
```

## Configure Prometheus scraping

Set up Prometheus to scrape metrics from your Flight server.

### Prometheus configuration

Add to `prometheus.yml`:

```yaml
scrape_configs:
  - job_name: 'xorq-flight'
    static_configs:
      - targets: ['localhost:9090']
    scrape_interval: 15s
```

**What happens**:

- Prometheus scrapes metrics every 15 seconds
- Metrics are stored in Prometheus time-series database
- You can query metrics using PromQL

### Verify scraping

Check that Prometheus is scraping:

1. Open Prometheus UI: `http://localhost:9090` (Prometheus default port)
2. Go to Status → Targets
3. Verify `xorq-flight` target is UP

**Expected status**: `UP` (green)

## Set up alerting

Create alert rules to detect issues early.

### Alert on high latency

Alert when P95 latency exceeds 1 second:

```yaml
# prometheus-alerts.yml
groups:
  - name: xorq_alerts
    rules:
      - alert: HighLatency
        expr: histogram_quantile(0.95, flight_server_request_duration_seconds) > 1.0
        for: 5m
        annotations:
          summary: "High latency detected"
          description: "P95 latency is {{ $value }}s"
```

**What happens**:

- Alert fires when P95 latency > 1s for 5 minutes
- Alert is sent to your notification channel (email, Slack, etc.)

### Alert on error rate

Alert when error rate is high:

```yaml
- alert: HighErrorRate
  expr: rate(flight_server_requests_total{status="error"}[5m]) > 0.1
  for: 5m
  annotations:
    summary: "High error rate"
    description: "Error rate is {{ $value }} errors/sec"
```

**Note**: Error status labels depend on your implementation. Adjust the query based on your error handling.

### Load alert rules

Add to `prometheus.yml`:

```yaml
rule_files:
  - "prometheus-alerts.yml"
```

Restart Prometheus to load the rules.

## Create Grafana dashboards

Visualize metrics in Grafana.

### Add Prometheus data source

1. Go to Configuration → Data Sources
2. Add Prometheus
3. Set URL: `http://localhost:9090` (your Prometheus server)
4. Click Save & Test

### Create dashboard panels

**Request rate panel**:

- Query: `rate(flight_server_requests_total[5m])`
- Visualization: Time series
- Title: "Request Rate"

**Latency panel**:

- Query: `histogram_quantile(0.95, flight_server_request_duration_seconds)`
- Visualization: Time series
- Title: "P95 Latency"

**Throughput panel**:

- Query: `rate(flight_server_rows_total[5m])`
- Visualization: Time series
- Title: "Rows per Second"

**Active streams panel**:

- Query: `flight_server_active_streams`
- Visualization: Gauge
- Title: "Active Streams"

## OpenTelemetry tracing

Xorq uses OpenTelemetry for distributed tracing. Configure it to view traces in your observability platform.

### Configure OpenTelemetry

Set environment variables:

```bash
export OTEL_SERVICE_NAME="xorq-flight-server"
export OTEL_EXPORTER_OTLP_ENDPOINT="http://localhost:4317"
export OTEL_EXPORTER_OTLP_PROTOCOL="grpc"
```

Or use a `.env` file:

```bash
OTEL_SERVICE_NAME=xorq-flight-server
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
OTEL_EXPORTER_OTLP_PROTOCOL=grpc
```

**What happens**:

- Traces are automatically exported when OpenTelemetry is configured
- Traces show request flow through your system
- View traces in your observability platform (Jaeger, Grafana Cloud, etc.)

### View traces

Traces are available in your OpenTelemetry-compatible observability platform:

- **Request spans**: Each RPC call creates a span
- **Timing information**: Duration for each span
- **Error information**: Errors are recorded in spans
- **Service dependencies**: See how services interact

## Troubleshooting

Common issues when setting up monitoring.

### Issue: Metrics endpoint not accessible

**Error**: `curl http://localhost:9090/metrics` returns connection refused

**Cause**: Metrics not enabled or wrong port.

**Fix**:

1. Verify `--prometheus-port` is set:
   ```bash
   xorq serve-unbound builds/<hash> --prometheus-port 9090
   ```

2. Check server logs for:
   ```
   Prometheus metrics available at :9090
   ```

3. Verify dependencies are installed:
   ```bash
   pip list | grep prometheus
   pip list | grep opentelemetry-exporter-prometheus
   ```

### Issue: No metrics in Prometheus

**Error**: Prometheus shows no data for `xorq-flight` target

**Cause**: Prometheus not scraping or wrong endpoint.

**Fix**:

1. Check Prometheus targets: Status → Targets
2. Verify target URL matches your server: `localhost:9090`
3. Check Prometheus logs for scraping errors
4. Verify metrics endpoint is accessible:
   ```bash
   curl http://localhost:9090/metrics | head -20
   ```

### Issue: Metrics show zero values

**Error**: All metrics are 0 even after requests

**Cause**: No requests have been made or metrics not recording.

**Fix**:

1. Make a request to your Flight server
2. Wait a few seconds for metrics to update
3. Check metrics again:
   ```bash
   curl http://localhost:9090/metrics | grep requests_total
   ```

### Issue: Prometheus dependencies missing

**Error**: Server logs show: `Prometheus support requires 'opentelemetry-exporter-prometheus' and 'prometheus-client'`

**Fix**:

Install the required packages:

```bash
pip install opentelemetry-exporter-prometheus prometheus-client
```

Restart your Flight server.

## Next steps

You now have monitoring set up for your Xorq deployments:

- [Set up CI/CD pipelines](setup_cicd_pipelines.qmd) - Automate deployments
- [Manage the compute catalog](manage_compute_catalog.qmd) - Organize builds
- [Deploy models to production](../ml_workflows/deploy_models_to_production.qmd) - Production deployment guide
