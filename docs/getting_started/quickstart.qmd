---
title: "Quickstart"
description: "Build and run your first Xorq ML pipeline in under five minutes"
icon: "pencil-square"
headline: "Get a first taste of Xorq"
---

After completing this guide, you have a working ML pipeline. This pipeline loads data, trains a model, and generates predictions. It uses Xorq's deferred execution model.

## What you'll build

In this quickstart, you:

1. Set up your environment and install Xorq
2. Initialize a project
3. Build a pipeline expression
4. Run your pipeline and save results
5. Serve a UDXF expression as an endpoint

The entire process takes about five minutes. By the end, you understand how Xorq transforms Python code into executable, servable pipelines.

## Step 1: Set up your environment and install Xorq

This step covers environment setup, Xorq installation, and verification.

### Check your Python version

::: {.callout-tip}
### Python version
Xorq requires Python 3.10 or higher. Check your version with `python --version`. If you need to install or update Python, then visit the [official Python downloads page](https://www.python.org/downloads/).
:::

### Create a virtual environment

Create and activate a virtual environment:

::: {.panel-tabset}

### macOS/Linux
```bash
python -m venv .venv
source .venv/bin/activate
```

### Windows
```bash
python -m venv .venv
.venv\Scripts\activate
```

:::

### Update pip

Before installing Xorq, update pip to the latest version. This avoids compatibility issues:
```bash
python -m pip install --upgrade pip
```

### Install Xorq

Now install Xorq using your preferred package manager:

::: {.panel-tabset}

### pip (macOS/Linux/Windows)
```bash
pip install "xorq[examples]"
```

### nix
```bash
nix run github:xorq-labs/xorq
```

:::

### Verify installation

Verify your installation by checking the version. Open a Python shell:
```bash
python
```

::: {.callout-note}
If `python` does not work, then try `python3` instead.
:::

Import Xorq and check the version:
```python
import xorq
xorq.__version__
```

You see a version number like `'0.3.4'`.

Exit the Python shell:
```python
exit()
```

If you see a version number, then Xorq is installed correctly.

With Xorq installed, the next step is to create your first project.

## Step 2: Initialize a project

Create a new Xorq project using the built-in penguins template. This template demonstrates a complete ML workflow with the Palmer Penguins dataset:
```bash
xorq init -t penguins -p penguins_example # <1>
cd penguins_example # <2>
```
1. Creates a new project called penguins_example using the penguins template.
2. Moves into the project directory.

The template generates an `expr.py` file. This file contains a complete ML pipeline with data loading, train/test splitting, model training, and prediction.


With your project initialized, the next step is to build it into an executable format.

## Step 3: Build your expression

Convert your pipeline into a serialized, executable format using the `build` command:
```bash
xorq build expr.py
```

**Output:**
```
Building expr from expr.py
Written 'expr' to builds/12287e173c17
builds/12287e173c17
```

The build creates a directory (like `builds/12287e173c17`) containing your serialized pipeline. This hash uniquely identifies your build.

![](../../images/quickstart/build-output-hash.png)

With your pipeline built, the next step is to run it and see results.


## Step 4: Run your pipeline

Execute your built pipeline and view the results. Replace `<BUILD_HASH>` with the hash from your build output in step 3:

::: {.callout-warning}
### Windows users
Skip the first tab and go straight to "Save to file". Running without an output file may cause issues on Windows.
:::

::: {.panel-tabset}

### View results
```bash
xorq run builds/<BUILD_HASH>
```

### Save to file
```bash
xorq run builds/<BUILD_HASH> -o predictions.parquet
```

### Limit output
```bash
xorq run builds/<BUILD_HASH> --limit 10 -o predictions.parquet
```

:::

The command saves prediction results to `predictions.parquet`. You can open this file with any Parquet-compatible tool. Compatible tools include pandas, DuckDB, or Polars.

With your pipeline running locally, the next step is to serve a UDXF expression as an endpoint.


## Step 5: Serve a UDXF expression

Serve a User-Defined Exchange Function (UDXF) as an API endpoint using Arrow Flight. UDXFs enable distributed data processing over the network. This example creates a simple transformation function that you can serve and query.

### Create a simple UDXF example

Create a new file called `udxf_example.py` in your working directory:

```python
# udxf_example.py
import pandas as pd
import xorq.api as xo

# <1>
def add_computed_column(df: pd.DataFrame) -> pd.DataFrame:
    """Add a computed column that doubles the input value."""
    result = df.copy()
    result["doubled"] = result["value"] * 2
    return result

# <2>
input_schema = xo.schema({"value": "int64"})
output_schema = xo.schema({"value": "int64", "doubled": "int64"})

# <3>
con = xo.connect()
input_table = xo.memtable({"value": [1, 2, 3, 4, 5]}, schema=input_schema)

# <4>
expr = xo.expr.relations.flight_udxf(
    input_table,
    process_df=add_computed_column,
    maybe_schema_in=input_schema,
    maybe_schema_out=output_schema,
    con=con,
    make_udxf_kwargs={
        "name": "double_value",
        "command": "double_value"
    }
)
```
1. Defines a transformation function that doubles input values.
2. Specifies input and output schemas for type safety.
3. Creates a simple input table with test data.
4. Creates the UDXF expression with the transformation function.

### Build the UDXF expression

Build the expression:

```bash
xorq build udxf_example.py --expr-name expr
```

This creates a second `<HASH>` in your `builds/<HASH>/` directory with your serialized UDXF expression. 

![](../../images/quickstart/second-hash.png)

### Start the Flight server

Start the Flight server with your built UDXF expression. Replace `<BUILD_HASH>` with the second hash from your build output:

```bash
xorq serve-flight-udxf --port 8001 builds/<BUILD_HASH>
```

Your UDXF is now running as an endpoint on `localhost:8001`. Keep this terminal window open while you query it.

### Query your served UDXF

With the server running, create a new Python file called `query_udxf.py`:

```python
# query_udxf.py
import xorq.api as xo

# <1>
client = xo.flight.client.FlightClient(port=8001)

# <2>
test_data = xo.memtable({"value": [10, 20, 30]}, schema=xo.schema({"value": "int64"}))

# <3>
fut, rbr = client.do_exchange("double_value", test_data)
result_df = rbr.read_pandas()

# <4>
print("Input values:")
print(test_data.execute())
print("\nOutput with doubled values:")
print(result_df)
```
1. Connects to the Flight server on port 8001.
2. Creates test data with values to double.
3. Executes the UDXF via Flight's do_exchange protocol.
4. Prints both input and output for comparison.

### Run the query script

Run the script:

```bash
python query_udxf.py
```

You see output showing the input values and their doubled counterparts. The UDXF processed your data remotely and returned the transformed results.

With querying complete, the next step is to learn about deploying specific expressions.

## Deploy a specific expression 

For deployments, you can serve a specific built expression from the penguins template as an endpoint using `serve-unbound`. This allows you to expose a particular expression as a Catalog service.

### Start the deployment server


Open a new terminal and run:

```bash
xorq serve-unbound builds/<BUILD_HASH> --host localhost --port 8001 --to_unbind_hash da8ba93cc97709f4ad9502e16d71e8e3
```

::: {.callout-important}
The hash `da8ba93cc97709f4ad9502e16d71e8e3` is specific to the penguins template. When you build your own pipelines, you generate different hashes. For this tutorial, use the exact hash shown above.
:::

### View your results

With the server running, you can query the penguins expression using the Flight client. 

Run the script:

```bash
python query_udxf.py
```
![](../../images/quickstart/quickstart-server-running.png)

The output shows penguin measurements alongside their predicted species classifications.

## What you built

You just built your first Xorq ML pipeline. You initialized a project, built it into a portable format, ran it to generate predictions, and served it as an API endpoint.

The entire workflow used Xorq's deferred execution model. No computation happened until you explicitly ran or queried the pipeline.

## Next steps

Continue learning:

- [Your first expression](/getting_started/your_first_expression.qmd) shows you how to build expressions from scratch without templates.
- [Understand deferred execution](/tutorials/core_tutorials/understand_deferred_execution.qmd) explains how Xorq builds computation graphs before executing them.
- [Explore caching](/tutorials/core_tutorials/explore_caching.qmd) demonstrates how Xorq caches results to speed up your workflows.
- [Your first UDXF](/tutorials/ai_tutorials/your_first_udxf.qmd) teaches you how to create custom exchange functions like the one you just served.
- [Join the community](https://discord.gg/8Kma9DhcJG) on Discord to get help and share your projects.