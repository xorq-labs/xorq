---
title: 'Use deferred fit and predict'
---

This tutorial shows you how to use deferred execution for model fitting and prediction. You'll learn when computation actually happens and how to leverage caching for ML workflows.

By the end, you'll understand how to build complex ML pipelines that defer expensive operations until the right moment.

## Why defer ML operations?

Model training is expensive. Loading data, fitting models, and making predictions can take minutes or hours on large datasets. Deferred execution lets Xorq:

- Optimize the full workflow before running anything
- Cache trained models for reuse
- Avoid redundant computations
- Let you build complex pipelines step by step

Think of deferred execution as writing a recipe before cooking—you can see the whole process and make improvements before spending resources.

:::{.callout-tip}
### Deferred fit and predict
When you defer both fitting and prediction, Xorq can cache the fitted model, skip unnecessary recomputations, and optimize data flow. This saves time and resources.
:::

## Understanding deferred fit

Let's start by fitting a model the deferred way:

```{python}
import xorq.api as xo
from sklearn.linear_model import LinearRegression
from xorq.ml import deferred_fit_predict_sklearn
import xorq.vendor.ibis.expr.datatypes as dt

# <1>
import pandas as pd
import numpy as np

X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])
y = np.dot(X, np.array([1, 2])) + 3
df = pd.DataFrame(np.hstack((X, y[:, np.newaxis]))).rename(
    columns=lambda x: chr(x + ord("a"))
)

# <2>
con = xo.connect()
table = con.register(df, "training_data")

# <3>
features = ("a", "b")
target = "c"

print("Data loaded:")
print(table.execute().head())
```
1. Create simple training data (y = 1*a + 2*b + 3).
2. Register the data as a Xorq table.
3. Define feature and target columns.

So far, we've loaded data but haven't trained anything yet.

## Create a deferred model

Now let's create a deferred model that won't fit until we explicitly execute:

```{python}
# <1>
deferred_model = deferred_fit_predict_sklearn(
    cls=LinearRegression,
    return_type=dt.float64
)

# <2>
print(f"Deferred model created: {deferred_model}")
print("No fitting has happened yet!")
```
1. Create a deferred version of LinearRegression.
2. At this point, no model has been trained.

The `deferred_fit_predict_sklearn` function creates a template for fitting. It knows what model to use and what return type to expect, but it doesn't fit anything until you execute.

## Fit and predict (deferred)

Let's fit the model and create predictions, all without executing:

```{python}
# <1>
(model_expr, model_udaf, predict_func) = deferred_model(
    expr=table,
    target=target,
    features=features
)

# <2>
predictions = table.mutate(
    predicted=predict_func.on_expr(table).name("predicted")
)

# <3>
print("Built prediction expression (not executed yet)")
print(f"Expression type: {type(predictions)}")
```
1. Call the deferred model with your data—this returns expressions, not results.
2. Add a prediction column to the table.
3. Still no computation! We've just built the expression graph.

At this point, Xorq knows:
- What data to use for training
- What model to fit
- Where to apply predictions

But it hasn't executed anything yet.

:::{.callout-note}
### Three return values
`deferred_fit_predict_sklearn()` returns three values: the model expression, a model UDAF (user-defined aggregate function), and a predict function. You use the predict function to create prediction expressions.
:::

## Execute and see results

Now trigger computation by executing:

```{python}
# <1>
print("Executing predictions...")
result = predictions.execute()

# <2>
print("\nResults:")
print(result[["c", "predicted"]])

# <3>
print(f"\nPredictions match expected values: {np.allclose(result['c'], result['predicted'])}")
```
1. This is when Xorq fits the model and makes predictions.
2. View the actual vs predicted values.
3. Check that predictions are accurate (should be perfect for this linear data).

The moment you called `.execute()`, Xorq:
1. Loaded the training data
2. Fitted the LinearRegression model
3. Applied the model to make predictions
4. Returned the results

## Add caching for speed

Let's see how caching speeds up repeated executions:

```{python}
from xorq.caching import ParquetStorage

# <1>
storage = ParquetStorage(source=con)

# <2>
(cached_model_expr, cached_udaf, cached_predict) = deferred_model(
    expr=table,
    target=target,
    features=features,
    storage=storage
)

# <3>
cached_predictions = table.mutate(
    predicted=cached_predict.on_expr(table).name("predicted")
)

# <4>
print("First execution (trains model, then caches):")
result1 = cached_predictions.execute()

# <5>
print("\nSecond execution (hits cache, skips training):")
result2 = cached_predictions.execute()

print("\nResults are identical:", result1.equals(result2))
```
1. Create storage for caching.
2. Create a deferred model with caching enabled.
3. Build prediction expression (deferred).
4. First execution trains and caches the model.
5. Second execution retrieves the cached model—much faster!

Caching is especially valuable when training takes minutes or hours. Once cached, subsequent runs skip the expensive fit operation.

:::{.callout-tip}
### Caching saves time
With caching, Xorq stores the fitted model. If you run the same expression again with the same data, Xorq retrieves the cached model instead of retraining. This is huge for expensive models.
:::

## Deferred fit with Step

You can also use deferred execution with the `Step` API:

```{python}
from xorq.expr.ml import Step

# <1>
step = Step(typ=LinearRegression)

# <2>
fitted_step = step.fit(
    expr=table,
    features=features,
    target=target,
    storage=storage
)

# <3>
step_predictions = table.mutate(
    predicted=fitted_step.predict_raw(table, name="predicted")
)

# <4>
result = step_predictions.execute()
print("\nStep-based predictions:")
print(result[["c", "predicted"]].head())
```
1. Create a Step wrapping LinearRegression.
2. Fit the step with caching—this executes and caches.
3. Build prediction expression.
4. Execute to get predictions.

The `Step` API gives you the same deferred execution benefits with a cleaner interface.

## Compare: immediate vs deferred

Let's compare what happens with immediate execution versus deferred:

```{python}
# <1>
# Immediate approach: train right away
immediate_df = table.execute()
immediate_model = LinearRegression()
immediate_model.fit(immediate_df[list(features)], immediate_df[target])
immediate_predictions = immediate_model.predict(immediate_df[list(features)])

print("Immediate approach: Model trained immediately")

# <2>
# Deferred approach: train only when executing
deferred_expr = table.mutate(
    predicted=cached_predict.on_expr(table).name("predicted")
)
print("Deferred approach: Expression built, no training yet")

# <3>
deferred_result = deferred_expr.execute()
print("Deferred approach: Model trained on execute()")
```
1. Immediate approach trains as soon as you call `.fit()`.
2. Deferred approach builds an expression without training.
3. Training happens only when you execute.

The deferred approach gives Xorq room to optimize before running expensive operations.

:::{.callout-warning}
### Avoid early execution
If you execute too early (like converting to pandas before building your full pipeline), you lose the benefits of deferred execution. Keep operations as expressions until you're ready to compute.
:::

## Build complex deferred workflows

Deferred execution shines when you have complex workflows with multiple steps:

```{python}
# <1>
workflow = (
    table
    .filter(xo._.a > 1)  # Deferred filter
    .mutate(
        predicted=cached_predict.on_expr  # Deferred prediction
    )
    .mutate(
        error=xo._.c - xo._.predicted  # Deferred error calculation
    )
    .agg(
        mean_error=xo._.error.mean()  # Deferred aggregation
    )
)

# <2>
print("Built complex workflow (not executed)")
print(f"Expression: {workflow}")

# <3>
result = workflow.execute()
print(f"\nMean prediction error: {result['mean_error'][0]:.6f}")
```
1. Chain multiple deferred operations: filter, predict, calculate error, aggregate.
2. The full workflow is built but not executed.
3. Execute once to run the entire pipeline.

Xorq sees the whole workflow and can optimize before running. This is powerful for complex ML pipelines.

## When computation happens

Let's make it crystal clear when computation actually happens:

```{python}
# <1>
print("Creating deferred model... (no computation)")
model = deferred_fit_predict_sklearn(cls=LinearRegression, return_type=dt.float64)

# <2>
print("Building fit expression... (no computation)")
(m_expr, m_udaf, predict) = model(expr=table, target=target, features=features)

# <3>
print("Building prediction expression... (no computation)")
pred_expr = table.mutate(predicted=predict.on_expr(table).name("predicted"))

# <4>
print("Calling execute()... (COMPUTATION HAPPENS HERE)")
result = pred_expr.execute()

print(f"Results: {len(result)} rows")
```
1. Creating the deferred model template—no computation.
2. Calling the model with data—no computation yet.
3. Building prediction expression—still no computation.
4. Executing the expression—computation happens now!

Only `.execute()` (or similar methods like `.to_pandas()`, `.to_pyarrow()`) trigger computation.

## Complete example

Here's a full workflow with deferred fit, predict, and caching:

```python
import xorq.api as xo
from sklearn.linear_model import LinearRegression
from xorq.ml import deferred_fit_predict_sklearn
from xorq.caching import ParquetStorage
import xorq.vendor.ibis.expr.datatypes as dt

# Setup
con = xo.connect()
storage = ParquetStorage(source=con)

# Load data (your actual data source here)
table = con.register(your_dataframe, "data")
features = ("feature1", "feature2")
target = "target_column"

# Create deferred model with caching
deferred_model = deferred_fit_predict_sklearn(
    cls=LinearRegression,
    return_type=dt.float64
)

# Fit and predict (deferred)
(model_expr, model_udaf, predict_func) = deferred_model(
    expr=table,
    target=target,
    features=features,
    storage=storage
)

# Build prediction pipeline
predictions = (
    table
    .mutate(predicted=predict_func.on_expr(table).name("predicted"))
    .mutate(error=xo._.target_column - xo._.predicted)
)

# Execute once to run everything
result = predictions.execute()
print(result[["target_column", "predicted", "error"]].head())
```

## Next steps

You now understand deferred fit and predict. Explore more:

- [Explore caching](../core_tutorials/explore_caching.qmd) dives deeper into caching strategies
- [Train your first model](train_your_first_model.qmd) shows the basics of model training
- [Understand Step and Pipeline](understand_step_and_pipeline.qmd) explains the ML abstractions in depth
