---
title: 'Split data for training'
---

This tutorial teaches you how to split data for model training and evaluation. You'll learn how to create train, test, validation, and holdout splits with Xorq's deterministic splitting functions.

By the end, you'll know how to properly partition data for ML workflows.

## Why split your data?

Model evaluation requires separating training data from test data. You train on one portion, then evaluate on unseen data to measure real-world performance.

Without proper splits, you risk overfitting—your model memorizes the training data but performs poorly on new data.

:::{.callout-tip}
### Deterministic splits
Xorq's splits are deterministic—you get the same partitions every time with the same random seed. This makes your experiments reproducible.
:::

## Simple train/test split

The most common split is train/test with an 80/20 or 75/25 ratio:

```{python}
import xorq.api as xo

# <1>
con = xo.connect()
iris = xo.examples.iris.fetch(backend=con)

# <2>
train, test = xo.train_test_splits(
    iris,
    unique_key="sepal_length",
    test_sizes=0.25,
    num_buckets=1000,
    random_seed=42
)

# <3>
train_count = train.count().execute()
test_count = test.count().execute()
total = train_count + test_count

# <4>
print(f"Train size: {train_count} ({train_count/total:.1%})")
print(f"Test size: {test_count} ({test_count/total:.1%})")
```
1. Load the Iris dataset.
2. Split into train (75%) and test (25%) using a unique key.
3. Count rows in each partition.
4. Verify the split ratios.

The `unique_key` parameter specifies which column to use for hashing—this determines how rows are assigned to partitions.

:::{.callout-note}
### How splitting works
Xorq hashes the unique key column to assign each row to a bucket. The bucket number determines which partition the row goes into. This ensures the same rows always end up in the same partition with the same random seed.
:::

## Multi-partition splits

For more complex workflows, you might want train, validation, test, and holdout sets:

```{python}
# <1>
partition_info = {
    "holdout": 0.1,
    "test": 0.2,
    "validation": 0.3,
    "training": 0.4
}

# <2>
holdout, test, validation, training = xo.train_test_splits(
    iris,
    unique_key="sepal_length",
    test_sizes=list(partition_info.values()),
    num_buckets=1000,
    random_seed=42
)

# <3>
import pandas as pd
counts = pd.Series({
    "holdout": holdout.count().execute(),
    "test": test.count().execute(),
    "validation": validation.count().execute(),
    "training": training.count().execute()
})

total = counts.sum()

# <4>
print("Partition sizes:")
for name, count in counts.items():
    print(f"{name.upper()}: {count} ({count/total:.1%})")
```
1. Define the desired split ratios (must sum to 1.0).
2. Create four mutually exclusive partitions.
3. Count rows in each partition.
4. Verify the ratios match what we requested.

Each partition is a separate table expression you can use independently.

## Use calc_split_column for manual control

Sometimes you want more control over splits. Use `calc_split_column` to create a split column, then filter manually:

```{python}
# <1>
split_column = xo.calc_split_column(
    iris,
    name="partition",
    unique_key="sepal_length",
    test_sizes=[0.1, 0.2, 0.3, 0.4],
    num_buckets=1000,
    random_seed=42
)

# <2>
table_with_split = iris.mutate(split_column)

# <3>
training_data = table_with_split.filter(xo._.partition == 3)
test_data = table_with_split.filter(xo._.partition == 1)

# <4>
print("Split column distribution:")
result = (
    table_with_split
    .group_by("partition")
    .agg(count=xo._.partition.count())
    .order_by("partition")
    .execute()
)
print(result)
```
1. Create a column that assigns each row to a partition (0, 1, 2, or 3).
2. Add the split column to your table.
3. Filter to get specific partitions.
4. Count rows in each partition.

This approach gives you a single table with partition labels, which can be easier to manage than separate table expressions.

:::{.callout-tip}
### Split column pattern
The split column pattern is useful when you want to:
- Keep all data in one table
- Dynamically change which partition you're working with
- Pass partition labels to downstream processing
:::

## Understanding unique_key

The `unique_key` parameter is crucial—it determines how Xorq assigns rows to partitions:

```{python}
# <1>
# Same unique_key = same split
train1, test1 = xo.train_test_splits(
    iris,
    unique_key="sepal_length",
    test_sizes=0.25,
    num_buckets=100,
    random_seed=42
)

# <2>
# Different unique_key = different split
train2, test2 = xo.train_test_splits(
    iris,
    unique_key="species",
    test_sizes=0.25,
    num_buckets=100,
    random_seed=42
)

# <3>
print(f"train1 count: {train1.count().execute()}")
print(f"train2 count: {train2.count().execute()}")
print("Different unique keys produce different splits")
```
1. Split using sepal_length as the unique key.
2. Split using species as the unique key.
3. The splits are different because hashing different columns produces different distributions.

Choose a unique key that makes sense for your data. Common choices:
- A true unique ID column (user ID, transaction ID)
- A high-cardinality column (timestamps, random IDs)
- A combination hash if you need entity-level splitting

## Deterministic splits with random_seed

The `random_seed` parameter makes splits reproducible:

```{python}
# <1>
train_a, test_a = xo.train_test_splits(
    iris,
    unique_key="sepal_length",
    test_sizes=0.25,
    num_buckets=100,
    random_seed=42
)

# <2>
train_b, test_b = xo.train_test_splits(
    iris,
    unique_key="sepal_length",
    test_sizes=0.25,
    num_buckets=100,
    random_seed=42
)

# <3>
# These should be identical
print(f"train_a count: {train_a.count().execute()}")
print(f"train_b count: {train_b.count().execute()}")
print("Same seed produces identical splits!")

# <4>
train_c, test_c = xo.train_test_splits(
    iris,
    unique_key="sepal_length",
    test_sizes=0.25,
    num_buckets=100,
    random_seed=99
)

print(f"train_c count: {train_c.count().execute()}")
print("Different seed produces different split")
```
1. Create a split with random_seed=42.
2. Create another split with the same random_seed=42.
3. Verify that the splits are identical.
4. Change the random_seed to get a different split.

Always use a fixed random seed for reproducible experiments.

:::{.callout-warning}
### Fix your random seed
In production, use a fixed random seed so your train/test splits don't change between runs. Changing splits makes it impossible to compare model performance across experiments.
:::

## Practical example: training workflow

Here's a complete training workflow with proper splits:

```{python}
from sklearn.neighbors import KNeighborsClassifier
from xorq.expr.ml import Step

# <1>
train, test = xo.train_test_splits(
    iris,
    unique_key="sepal_length",
    test_sizes=0.25,
    num_buckets=100,
    random_seed=42
)

# <2>
target = "species"
features = tuple(iris.drop(target).columns)

# <3>
model = Step(typ=KNeighborsClassifier, n_neighbors=5)
fitted_model = model.fit(
    expr=train,  # Train on training set only
    features=features,
    target=target
)

# <4>
test_predictions = test.mutate(
    predicted=fitted_model.predict_raw(test, name="predicted")
)

# <5>
accuracy = (
    test_predictions
    .mutate(correct=xo._.species == xo._.predicted)
    .agg(accuracy=xo._.correct.mean())
    .execute()
)

print(f"Test accuracy: {accuracy['accuracy'][0]:.2%}")
```
1. Split data into train and test sets.
2. Define features and target.
3. Train the model using only the training set.
4. Make predictions on the test set (unseen data).
5. Calculate accuracy on the test set.

This workflow trains on one portion of data and evaluates on another, giving you an honest assessment of model performance.

## Advanced: stratified-like splits

While Xorq doesn't have built-in stratified splitting, you can approximate it by using a class label as part of your unique key:

```{python}
# <1>
# Create a composite key that includes the target
iris_with_key = iris.mutate(
    composite_key=xo._.species.cast("string") + "_" + xo._.sepal_length.cast("string")
)

# <2>
train_strat, test_strat = xo.train_test_splits(
    iris_with_key,
    unique_key="composite_key",
    test_sizes=0.25,
    num_buckets=100,
    random_seed=42
)

# <3>
print("Training set distribution:")
train_dist = (
    train_strat
    .group_by("species")
    .agg(count=xo._.species.count())
    .execute()
)
print(train_dist)

print("\nTest set distribution:")
test_dist = (
    test_strat
    .group_by("species")
    .agg(count=xo._.species.count())
    .execute()
)
print(test_dist)
```
1. Create a composite key that combines the target class with another column.
2. Split using the composite key.
3. Check class distribution in train and test sets.

This approach helps balance class distributions across splits.

## Complete example

Here's a full workflow with multi-partition splits:

```python
import xorq.api as xo

# Load data
con = xo.connect()
iris = xo.examples.iris.fetch(backend=con)

# Create train, validation, test splits
train, validation, test = xo.train_test_splits(
    iris,
    unique_key="sepal_length",
    test_sizes=[0.6, 0.2, 0.2],  # 60% train, 20% val, 20% test
    num_buckets=100,
    random_seed=42
)

# Verify splits
train_count = train.count().execute()
val_count = validation.count().execute()
test_count = test.count().execute()
total = train_count + val_count + test_count

print(f"Train: {train_count} ({train_count/total:.1%})")
print(f"Validation: {val_count} ({val_count/total:.1%})")
print(f"Test: {test_count} ({test_count/total:.1%})")

# Now use these splits for training, tuning, and evaluation
```

## Next steps

You now know how to split data properly. Continue learning:

- [Train your first model](train_your_first_model.qmd) shows how to train on split data
- [Explore model evaluation](explore_model_evaluation.qmd) demonstrates evaluating multiple models
- [Use deferred fit and predict](use_deferred_fit_predict.qmd) covers advanced ML patterns
