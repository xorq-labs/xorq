---
title: "10-minute tour of Xorq"
icon: "clock"
headline: "Learn key concepts in a brief tutorial"
---

A quick tour of Xorq's core features. This tutorial covers multi-engine operations, caching, UDXF nodes and Profiles.
Xorq also ships with a CLI for quickly bootstrapping the creation, execution and serving of expressions. 

## Installation

```bash
pip install 'xorq[duckdb,examples]'
```

## Working with Data

Xorq leverage Ibis for working with data, for example:

```{python}
import xorq as xo 
from xorq import _

penguins = xo.examples.penguins.fetch(backend=xo.pandas.connect())

# Build a query - nothing executes yet
clean_penguins = (
    penguins
    .filter(
        _.bill_length_mm.isnull() == False,
        _.sex.isnull() == False
    )
    .select(['species', 'island', 'sex', 'bill_length_mm', 'body_mass_g'])
    .mutate(
        body_mass_kg=_.body_mass_g / 1000
    )
)

# Execute to see results
clean_penguins.execute()
```

For more info on data operations and transformations with Ibis, check the [Ibis docs](https://ibis-project.org/).

## Multi-Engine Operations

A core feature of Xorq is the capability of moving data between backends use `into_backend()`:

```{python}
# Move pandas data to DuckDB
ddb = xo.duckdb.connect()
ddb_penguins = clean_penguins.into_backend(ddb, "penguins_clean")

# Now use DuckDB for analytics
species_stats = (
    ddb_penguins
    .group_by(['species', 'island'])
    .agg([
        _.bill_length_mm.mean().name('avg_bill_length'),
        _.body_mass_g.mean().name('avg_body_mass'),
        _.count().name('penguin_count')
    ])
)

# Join across the same backend
enriched = (
    ddb_penguins
    .join(species_stats, ['species', 'island'], how='left')
    .mutate(
        bill_vs_avg=_.bill_length_mm - _.avg_bill_length,
        mass_vs_avg=_.body_mass_g - _.avg_body_mass
    )
)

enriched.execute()
```

## Caching

Xorq provides a caching mechanism that can write to Parquet or a source (DuckDB, Postgres) to avoid re-computation:

```{python}
from pathlib import Path
from xorq.caching import ParquetStorage

con = xo.connect()

# Set up caching
cache_storage = ParquetStorage(source=con, base_path=Path.cwd())

# Cache the result
cached_enriched = enriched.cache(storage=cache_storage)

# First execution computes and caches
result1 = cached_enriched.execute()

# Second execution uses cache
result2 = cached_enriched.execute()  # Much faster
```

## UDXF (User-Defined Exchange Functions)

UDXF are functions that spin an ephemeral Flight Server for the execution through a [DoExchange](https://arrow.apache.org/docs/format/Flight.html#exchanging-data):

```{python}
import pandas as pd

import xorq as xo

penguins = xo.examples.penguins.fetch(deferred=False)


def standardize_penguins(df: pd.DataFrame) -> pd.DataFrame:
    """
    Return a new DataFrame with penguin measurements standardized.
    """
    return df.dropna(
        subset=["bill_length_mm", "bill_depth_mm", "body_mass_g"], ignore_index=True
    ).assign(
        **{
            "bill_length_std": lambda t: t["bill_length_mm"]
            .sub(t["bill_length_mm"].mean())
            .div(t["bill_length_mm"].std()),
            "body_mass_std": lambda t: t["body_mass_g"]
            .sub(t["body_mass_g"].mean())
            .div(t["body_mass_g"].std()),
        }
    )


expr = penguins.select(
    "bill_length_mm", "bill_depth_mm", "flipper_length_mm", "body_mass_g"
)


my_udxf = xo.expr.relations.flight_udxf(
    process_df=standardize_penguins,
    maybe_schema_in=expr.schema(),
    maybe_schema_out=expr.schema()
    | xo.schema({"bill_length_std": "float", "body_mass_std": "float"}),
)

expr.pipe(my_udxf).execute()
```

## Profiles 

For persisting connections Xorq provides the [Profiles API](../../api_reference/backend_configuration/profiles_api.qmd), a Profile is a representation of a database connection that can be saved and loaded:

```{python}
import xorq as xo
from xorq import _  # column references
from xorq.vendor.ibis.backends.profiles import Profile

# Create a Profile from pandas connection
pandas_profile = Profile.from_con(xo.pandas.connect())

profile = Profile(
   con_name='postgres',
   kwargs_tuple=(
            ('host', '${POSTGRES_HOST}'),
            ('port', 5432),
            ('database', 'ibis_testing'),
            ('user', '${POSTGRES_USER}'),
            ('password', '${POSTGRES_PASSWORD}'),
        )
)

path = pandas_profile.save(alias="pandas_example", clobber=True)  # clobber for overwriting
```

The Profiles API supports serialization to  and deserialization from YAML, environment variable substitution, and security  checks to prevent sensitive information from being stored in plain text.

# Xorq CLI Commands

The `xorq` CLI provides powerful commands to build, run, and serve data pipelines. This section covers the essential commands you'll use in your workflow.

## Overview

Xorq separates pipeline definition from execution through its CLI:

```bash
xorq <command> [options]
```

## Core Commands

### `xorq init` – Initialize a Project

Quickly bootstrap a new Xorq project from templates:

```bash
# Use the Penguins ML template
xorq init -t penguins -p penguins_example
```

### `xorq build` - Compile Expressions

Convert Python expressions into serialized artifacts:

```bash
# Basic build
xorq build penguins_example/expr.py
```

You should see output similar to the following:

```bash
Building expr from penguins_example/expr.py
Written 'expr' to builds/5704ffbeade4
builds/5704ffbeade4
```

This means the artifact for the variable named `expr` in the file `expr.py` was written to  
`builds/5704ffbeade4`.

### `xorq run` – Execute Pipelines

Run compiled expressions with various output options:

```bash
# Run and display results
xorq run builds/5704ffbeade4
```

The above command runs the serialized artifact and discards the result. To permanently  
save the output, use:

```bash
# Save to file
xorq run builds/5704ffbeade4 -o results.parquet
```

### `xorq serve-unbound` – Deploy as Flight Server

Serve your pipeline as an Arrow Flight endpoint:

```bash
# Basic server
xorq serve-unbound builds/5704ffbeade4 b2370a29c19df8e1e639c63252dacd0e
```

### `xorq serve`

The [`xorq serve`](../../api_reference/cli/serve.qmd) command serves expressions that contain UDXF (User-Defined Exchange Functions) nodes via Apache Arrow Flight. 

For this command, we'll use the following `expr.py` file:

```python
import pandas as pd

import xorq as xo

penguins = xo.examples.penguins.fetch(deferred=False)


def standardize_penguins(df: pd.DataFrame) -> pd.DataFrame:
    """
    Return a new DataFrame with penguin measurements standardized.
    """
    return (
        df
        .dropna(subset=["bill_length_mm", "bill_depth_mm", "body_mass_g"], ignore_index=True)
        .assign(**{
            "bill_length_std": lambda t: t["bill_length_mm"].sub(t["bill_length_mm"].mean()).div(t["bill_length_mm"].std()),
            "body_mass_std": lambda t: t["body_mass_g"].sub(t["body_mass_g"].mean()).div(t["body_mass_g"].std()),
        })
    )


expr = penguins.select(
    "bill_length_mm", "bill_depth_mm", "flipper_length_mm", "body_mass_g"
)


my_udxf = xo.expr.relations.flight_udxf(
    process_df=standardize_penguins,
    maybe_schema_in=expr.schema(),
    maybe_schema_out=expr.schema() | {"bill_length_std": float, "body_mass_std": float},
)

pipeline = expr.pipe(my_udxf)


if __name__ == "__pytest_main__":
    pipeline.execute()
```

First, let's rebuild the expression:

```bash
xorq build penguins_example/expr.py
```

This produces the following output:

```bash
Building expr from penguins_example/expr.py
Written 'expr' to builds/cb63fef71027
builds/cb63fef71027
```

Now we can serve the expression:

```bash
xorq serve builds/cb63fef71027
```

## Summary

You've seen:

* **Multi-engine operations** for moving data between backends with `into_backend()`
* **Caching** deferred, for store expensive computation results
* **UDXF nodes** for creating reusable transformation functions
* **Profiles** for managing backend connections
* **CLI Commands** for building, running and serving expressions

Next steps: Explore [core concepts](../../core_concepts/index.qmd) or learn more about [UDXF nodes](../../core_concepts/flight_udxf.qmd).