---
title: "10-minute tour of Xorq"
icon: "clock"
headline: "Learn key concepts in a brief tutorial"
---

A quick tour of Xorq's core features. This tutorial covers multi-engine operations, caching, UDXF nodes and Profiles.

## Installation

```bash
pip install 'xorq[duckdb,examples]'
```

## Working with Data

Xorq leverage Ibis for working with data, for example:

```{python}
import xorq as xo 
from xorq import _

penguins = xo.examples.penguins.fetch(backend=xo.pandas.connect())

# Build a query - nothing executes yet
clean_penguins = (
    penguins
    .filter(
        _.bill_length_mm.isnull() == False,
        _.sex.isnull() == False
    )
    .select(['species', 'island', 'sex', 'bill_length_mm', 'body_mass_g'])
    .mutate(
        body_mass_kg=_.body_mass_g / 1000
    )
)

# Execute to see results
clean_penguins.execute()
```

For more info on data operations and transformations with Ibis, check the [Ibis docs](https://ibis-project.org/).

## Multi-Engine Operations

A core feature of Xorq is the capability of moving data between backends use `into_backend()`:

```{python}
# Move pandas data to DuckDB
ddb = xo.duckdb.connect()
ddb_penguins = clean_penguins.into_backend(ddb, "penguins_clean")

# Now use DuckDB for analytics
species_stats = (
    ddb_penguins
    .group_by(['species', 'island'])
    .agg([
        _.bill_length_mm.mean().name('avg_bill_length'),
        _.body_mass_g.mean().name('avg_body_mass'),
        _.count().name('penguin_count')
    ])
)

# Join across the same backend
enriched = (
    ddb_penguins
    .join(species_stats, ['species', 'island'], how='left')
    .mutate(
        bill_vs_avg=_.bill_length_mm - _.avg_bill_length,
        mass_vs_avg=_.body_mass_g - _.avg_body_mass
    )
)

enriched.execute()
```

## Caching

Xorq provides a caching mechanism that can write to Parquet or a source (DuckDB, Postgres) to avoid re-computation:

```{python}
from pathlib import Path
from xorq.caching import ParquetStorage

con = xo.connect()

# Set up caching
cache_storage = ParquetStorage(source=con, base_path=Path.cwd())

# Cache the result
cached_enriched = enriched.cache(storage=cache_storage)

# First execution computes and caches
result1 = cached_enriched.execute()

# Second execution uses cache
result2 = cached_enriched.execute()  # Much faster
```

## UDXF (User-Defined Exchange Functions)

UDXF are functions that spin an ephemeral Flight Server for the execution through a [DoExchange](https://arrow.apache.org/docs/format/Flight.html#exchanging-data):

```{python}
import pandas as pd

import xorq as xo

penguins = xo.examples.penguins.fetch(deferred=False)


def standardize_penguins(df: pd.DataFrame) -> pd.DataFrame:
    """
    Return a new DataFrame with penguin measurements standardized.
    """
    return df.dropna(
        subset=["bill_length_mm", "bill_depth_mm", "body_mass_g"], ignore_index=True
    ).assign(
        **{
            "bill_length_std": lambda t: t["bill_length_mm"]
            .sub(t["bill_length_mm"].mean())
            .div(t["bill_length_mm"].std()),
            "body_mass_std": lambda t: t["body_mass_g"]
            .sub(t["body_mass_g"].mean())
            .div(t["body_mass_g"].std()),
        }
    )


expr = penguins.select(
    "bill_length_mm", "bill_depth_mm", "flipper_length_mm", "body_mass_g"
)


my_udxf = xo.expr.relations.flight_udxf(
    process_df=standardize_penguins,
    maybe_schema_in=expr.schema(),
    maybe_schema_out=expr.schema()
    | xo.schema({"bill_length_std": "float", "body_mass_std": "float"}),
)

expr.pipe(my_udxf).execute()
```

## Profiles 

For persisting connections Xorq provides the [Profiles API](../../api_reference/backend_configuration/profiles_api.qmd), a Profile is a representation of a database connection that can be saved and loaded:

```{python}
import xorq as xo
from xorq import _  # column references
from xorq.vendor.ibis.backends.profiles import Profile

# Create a Profile from pandas connection
pandas_profile = Profile.from_con(xo.pandas.connect())

profile = Profile(
   con_name='postgres',
   kwargs_tuple=(
            ('host', '${POSTGRES_HOST}'),
            ('port', 5432),
            ('database', 'ibis_testing'),
            ('user', '${POSTGRES_USER}'),
            ('password', '${POSTGRES_PASSWORD}'),
        )
)

path = pandas_profile.save(alias="pandas_example", clobber=True)  # clobber for overwriting
```

The Profiles API supports serialization to  and deserialization from YAML, environment variable substitution, and security  checks to prevent sensitive information from being stored in plain text.


## Summary

You've seen:

* **Multi-engine operations** for moving data between backends with `into_backend()`
* **Caching** deferred, for store expensive computation results
* **UDXF nodes** for creating reusable transformation functions
* **Profiles** for managing backend connections

Next steps: Explore [core concepts](../../core_concepts/index.qmd) or learn more about [UDXF nodes](../../core_concepts/flight_udxf.qmd).