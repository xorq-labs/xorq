"""
Integration tests for sklearn â†” xorq interoperability.

Tests the following features:
- to_sklearn() round-trip for Step, FittedStep, Pipeline, FittedPipeline
- Packed format for transformers with dynamic schemas
- Mixin catch-alls for predictors (RegressorMixin, ClusterMixin)
- Transductive/fit-only estimators (TSNE, DBSCAN)
"""

import pandas as pd
import pytest

import xorq.api as xo
from xorq.expr.ml.fit_lib import (
    pack_transform_output,
    unpack_packed_column,
)
from xorq.expr.ml.pipeline_lib import (
    Pipeline,
    Step,
    has_structer_registration,
    is_fit_predict_only,
    is_fit_transform_only,
)


sklearn = pytest.importorskip("sklearn")


# =============================================================================
# Fixtures
# =============================================================================


@pytest.fixture(scope="module")
def sample_data():
    """Simple dataset for testing transformers and predictors."""
    return pd.DataFrame(
        {
            "feature_0": [1.0, 2.0, 3.0, 4.0, 5.0],
            "feature_1": [5.0, 4.0, 3.0, 2.0, 1.0],
            "category": ["a", "b", "a", "b", "a"],
            "target": [0, 1, 0, 1, 0],
        }
    )


@pytest.fixture(scope="module")
def expr(sample_data):
    """xorq expression from sample data."""
    return xo.memtable(sample_data)


@pytest.fixture(scope="module")
def numeric_features():
    return ("feature_0", "feature_1")


# =============================================================================
# Test: to_sklearn() for Step (unfitted)
# =============================================================================


class TestStepToSklearn:
    """Tests for Step.to_sklearn() method."""

    def test_step_to_sklearn_standard_scaler(self):
        """Step.to_sklearn() returns unfitted StandardScaler."""
        from sklearn.preprocessing import StandardScaler

        original = StandardScaler()
        step = Step.from_instance_name(original, name="scaler")
        result = step.to_sklearn()

        assert isinstance(result, StandardScaler)
        # Not fitted yet
        assert not hasattr(result, "mean_") or result.mean_ is None

    def test_step_to_sklearn_preserves_params(self):
        """Step.to_sklearn() preserves estimator parameters."""
        from sklearn.neighbors import KNeighborsClassifier

        original = KNeighborsClassifier(n_neighbors=7, weights="distance")
        step = Step.from_instance_name(original, name="knn")
        result = step.to_sklearn()

        assert result.n_neighbors == 7
        assert result.weights == "distance"


# =============================================================================
# Test: to_sklearn() for FittedStep
# =============================================================================


class TestFittedStepToSklearn:
    """Tests for FittedStep.to_sklearn() method."""

    def test_fitted_step_to_sklearn_transformer(self, expr, numeric_features):
        """FittedStep.to_sklearn() returns fitted transformer."""
        from sklearn.preprocessing import StandardScaler

        step = Step.from_instance_name(StandardScaler(), name="scaler")
        fitted_step = step.fit(expr, features=numeric_features)
        sklearn_model = fitted_step.to_sklearn()

        assert isinstance(sklearn_model, StandardScaler)
        # Should be fitted - has mean_ attribute
        assert hasattr(sklearn_model, "mean_")
        assert sklearn_model.mean_ is not None

    def test_fitted_step_to_sklearn_predictor(self, expr, numeric_features):
        """FittedStep.to_sklearn() returns fitted predictor."""
        from sklearn.linear_model import LogisticRegression

        step = Step.from_instance_name(LogisticRegression(max_iter=200), name="clf")
        fitted_step = step.fit(expr, features=numeric_features, target="target")
        sklearn_model = fitted_step.to_sklearn()

        assert isinstance(sklearn_model, LogisticRegression)
        # Should be fitted - has coef_ attribute
        assert hasattr(sklearn_model, "coef_")


# =============================================================================
# Test: to_sklearn() for Pipeline (unfitted)
# =============================================================================


class TestPipelineToSklearn:
    """Tests for Pipeline.to_sklearn() method."""

    def test_pipeline_to_sklearn_roundtrip(self):
        """Pipeline.to_sklearn() round-trip preserves structure."""
        from sklearn.linear_model import LogisticRegression
        from sklearn.pipeline import Pipeline as SklearnPipeline
        from sklearn.preprocessing import StandardScaler

        sklearn_pipe = SklearnPipeline(
            [
                ("scaler", StandardScaler()),
                ("clf", LogisticRegression(max_iter=200)),
            ]
        )

        xorq_pipe = Pipeline.from_instance(sklearn_pipe)
        sklearn_pipe_back = xorq_pipe.to_sklearn()

        assert isinstance(sklearn_pipe_back, SklearnPipeline)
        assert len(sklearn_pipe_back.steps) == 2
        assert sklearn_pipe_back.steps[0][0] == "scaler"
        assert sklearn_pipe_back.steps[1][0] == "clf"


# =============================================================================
# Test: to_sklearn() for FittedPipeline
# =============================================================================


class TestFittedPipelineToSklearn:
    """Tests for FittedPipeline.to_sklearn() method."""

    def test_fitted_pipeline_to_sklearn(self, expr, numeric_features):
        """FittedPipeline.to_sklearn() returns fitted sklearn Pipeline."""
        from sklearn.linear_model import LogisticRegression
        from sklearn.pipeline import Pipeline as SklearnPipeline
        from sklearn.preprocessing import StandardScaler

        sklearn_pipe = SklearnPipeline(
            [
                ("scaler", StandardScaler()),
                ("clf", LogisticRegression(max_iter=200)),
            ]
        )

        xorq_pipe = Pipeline.from_instance(sklearn_pipe)
        fitted_xorq = xorq_pipe.fit(expr, features=numeric_features, target="target")
        sklearn_fitted = fitted_xorq.to_sklearn()

        assert isinstance(sklearn_fitted, SklearnPipeline)
        # Should be fitted
        assert hasattr(sklearn_fitted.named_steps["scaler"], "mean_")
        assert hasattr(sklearn_fitted.named_steps["clf"], "coef_")

    def test_fitted_pipeline_can_predict(self, expr, numeric_features, sample_data):
        """Fitted sklearn pipeline from to_sklearn() can predict."""
        from sklearn.linear_model import LogisticRegression
        from sklearn.pipeline import Pipeline as SklearnPipeline
        from sklearn.preprocessing import StandardScaler

        sklearn_pipe = SklearnPipeline(
            [
                ("scaler", StandardScaler()),
                ("clf", LogisticRegression(max_iter=200)),
            ]
        )

        xorq_pipe = Pipeline.from_instance(sklearn_pipe)
        fitted_xorq = xorq_pipe.fit(expr, features=numeric_features, target="target")
        sklearn_fitted = fitted_xorq.to_sklearn()

        # Should be able to predict
        X_test = sample_data[list(numeric_features)]
        predictions = sklearn_fitted.predict(X_test)
        assert len(predictions) == len(X_test)


# =============================================================================
# Test: Mixin catch-alls
# =============================================================================


class TestMixinCatchAlls:
    """Tests for mixin catch-all registrations."""

    def test_regressor_mixin_returns_float64(self, expr, numeric_features):
        """RegressorMixin predictors return float64."""
        from sklearn.linear_model import Ridge

        step = Step.from_instance_name(Ridge(), name="ridge")
        fitted = step.fit(expr, features=numeric_features, target="target")

        # Should be able to predict without explicit registration
        result = fitted.predict(expr)
        assert result is not None

    @pytest.mark.skip(
        reason="KMeans has both transform and predict, which FittedStep doesn't support"
    )
    def test_cluster_mixin_works(self, expr, numeric_features):
        """ClusterMixin estimators work via catch-all (for inductive clusterers).

        NOTE: This test is skipped because KMeans has both transform() and predict()
        methods, which violates FittedStep's assumption that estimators are either
        transformers OR predictors (not both). This is a limitation in the current
        design that would need to be addressed in a future iteration.

        The ClusterMixin catch-all registration is still functional for estimators
        that only have predict() (not transform()).
        """
        from sklearn.cluster import KMeans

        step = Step.from_instance_name(KMeans(n_clusters=2, n_init=3), name="kmeans")
        fitted = step.fit(expr, features=numeric_features, target="target")
        result = fitted.predict(expr)
        assert result is not None


# =============================================================================
# Test: Packed format utilities
# =============================================================================


class TestPackedFormat:
    """Tests for packed format utilities."""

    def test_pack_transform_output(self):
        """pack_transform_output creates Array[Struct{key, value}] format."""
        from sklearn.preprocessing import StandardScaler

        df = pd.DataFrame({"a": [1.0, 2.0, 3.0], "b": [4.0, 5.0, 6.0]})
        scaler = StandardScaler()
        scaler.fit(df)

        packed = pack_transform_output(scaler, df, features=("a", "b"))

        assert isinstance(packed, pd.Series)
        assert len(packed) == 3
        # Each row should be a tuple of dicts with key/value
        first_row = packed.iloc[0]
        assert isinstance(first_row, tuple)
        assert all("key" in item and "value" in item for item in first_row)

    def test_unpack_packed_column(self):
        """unpack_packed_column converts packed format back to columns."""
        # Create packed data
        packed_data = [
            ({"key": "a", "value": 1.0}, {"key": "b", "value": 4.0}),
            ({"key": "a", "value": 2.0}, {"key": "b", "value": 5.0}),
            ({"key": "a", "value": 3.0}, {"key": "b", "value": 6.0}),
        ]
        df = pd.DataFrame({"id": [1, 2, 3], "transformed": packed_data})

        result = unpack_packed_column(df, col_name="transformed")

        assert "a" in result.columns
        assert "b" in result.columns
        assert "transformed" not in result.columns
        assert list(result["a"]) == [1.0, 2.0, 3.0]
        assert list(result["b"]) == [4.0, 5.0, 6.0]


# =============================================================================
# Test: Estimator mode detection
# =============================================================================


class TestEstimatorModeDetection:
    """Tests for estimator mode detection helpers."""

    def test_is_fit_transform_only(self):
        """is_fit_transform_only correctly identifies transductive embeddings."""
        from sklearn.manifold import TSNE

        assert is_fit_transform_only(TSNE) is True

    def test_is_fit_transform_only_regular_transformer(self):
        """is_fit_transform_only returns False for regular transformers."""
        from sklearn.preprocessing import StandardScaler

        assert is_fit_transform_only(StandardScaler) is False

    def test_is_fit_predict_only(self):
        """is_fit_predict_only correctly identifies transductive clusterers."""
        from sklearn.cluster import DBSCAN

        assert is_fit_predict_only(DBSCAN) is True

    def test_is_fit_predict_only_regular_clusterer(self):
        """is_fit_predict_only returns False for inductive clusterers."""
        from sklearn.cluster import KMeans

        assert is_fit_predict_only(KMeans) is False


# =============================================================================
# Test: Structer registration detection
# =============================================================================


class TestStructerRegistration:
    """Tests for Structer registration detection."""

    def test_has_structer_registration_for_registered_type(
        self, expr, numeric_features
    ):
        """has_structer_registration returns True for registered types."""
        from sklearn.preprocessing import StandardScaler

        scaler = StandardScaler()
        assert has_structer_registration(scaler, expr, numeric_features) is True

    def test_has_structer_registration_for_unregistered_type(
        self, expr, numeric_features
    ):
        """has_structer_registration returns False for unregistered types."""
        from sklearn.preprocessing import MinMaxScaler

        # MinMaxScaler is not explicitly registered in structer.py
        scaler = MinMaxScaler()
        result = has_structer_registration(scaler, expr, numeric_features)
        # Should be False since MinMaxScaler is not in the Structer registry
        assert result is False


# =============================================================================
# Test: Packed format fallback for unregistered transformers
# =============================================================================


class TestPackedFormatFallback:
    """Tests for packed format fallback for unregistered transformers."""

    def test_unregistered_transformer_uses_packed_format(self, expr, numeric_features):
        """Unregistered transformers fall back to packed format."""
        from sklearn.preprocessing import MinMaxScaler

        step = Step.from_instance_name(MinMaxScaler(), name="minmax")
        fitted = step.fit(expr, features=numeric_features)

        # Should be able to transform using packed format
        result = fitted.transform_raw(expr)
        assert result is not None


# =============================================================================
# Test: predict_proba() and decision_function()
# =============================================================================


class TestProbabilisticOutputs:
    """Tests for predict_proba() and decision_function() methods."""

    def test_predict_proba_returns_packed_format(self, expr, numeric_features):
        """predict_proba() returns packed format with class probabilities."""
        from sklearn.linear_model import LogisticRegression

        step = Step.from_instance_name(LogisticRegression(max_iter=200), name="clf")
        fitted = step.fit(expr, features=numeric_features, target="target")

        # Should return packed format
        result = fitted.predict_proba(expr, retain_others=False)
        assert result is not None
        assert "proba" in result.columns

    def test_predict_proba_raises_for_non_classifier(self, expr, numeric_features):
        """predict_proba() raises AttributeError for estimators without it."""
        from sklearn.linear_model import LinearRegression

        step = Step.from_instance_name(LinearRegression(), name="reg")
        fitted = step.fit(expr, features=numeric_features, target="target")

        with pytest.raises(AttributeError, match="does not have predict_proba"):
            fitted.predict_proba(expr)

    def test_decision_function_returns_packed_format(self, expr, numeric_features):
        """decision_function() returns packed format with decision values."""
        from sklearn.svm import SVC

        step = Step.from_instance_name(SVC(kernel="linear"), name="svc")
        fitted = step.fit(expr, features=numeric_features, target="target")

        # Should return packed format
        result = fitted.decision_function(expr, retain_others=False)
        assert result is not None
        assert "decision" in result.columns

    def test_decision_function_raises_for_non_svm(self, expr, numeric_features):
        """decision_function() raises AttributeError for estimators without it."""
        from sklearn.neighbors import KNeighborsClassifier

        step = Step.from_instance_name(KNeighborsClassifier(n_neighbors=3), name="knn")
        fitted = step.fit(expr, features=numeric_features, target="target")

        with pytest.raises(AttributeError, match="does not have decision_function"):
            fitted.decision_function(expr)
